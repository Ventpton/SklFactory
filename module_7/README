
Цель этого проекта построить модель, которая сможет классифицировать 10 разных моделей автомобилей.
Для обучение этой модели изначально были предоставлены около 15500 фотографий автомобилей для обучения.
10 Моделей распределены достаточно равномерно по папкам моделей. Окончательная тестирование модели
должно было проходить на совершенно отдельных фотографиях количество которых 6675.

Базовая модель основаная на сети Xception уже давала не плохии результаты в районе 92% правильно
определеных автомобилей. Задача стала как можно больше улучшить этот результат. 

Первое с чего я начал это было изучить предоставленые фотографии. Среди них я нашел какой-то процент
сильно узких фотографий, сильно затемненых, фотографии салонов автомобиля а не внешнего вида. Какие-то фотографии 
я посчитал лучше удалить, какие-то отредоктировать, особенно если на фотографии был рядом автомобиль другой модели
из 10 которых модель должна была классифицировать. Затем я решил добавить около 11000 фотографий для обучения. Фотографии
были взяты с интернет рынка автомобилей. Для аугментации я начал использовать библиотеку albumentations. Эта библиотека 
дает больше возможностей для аугментации картинок.

Я продолжил эксперементировать с сетью Xception и первым делом решил определиться с оптимайзером и learning rate.
Я перебрал несколько оптимайзеров и несколько learning rate и остался на Adam и learning rate 0.0001. Затем я 
я проэксперементировал с методом, который помогает отыскать хороший диапазон learning rate для обучения. Метод
заключается в обучении модели на изменяищемся learning rate, затем по loss графику смотрится на каком диапазоне
learning rate график максимальней уменьшался, тот промежуток learning rate считается хорошим для обучения. Потом была
попытка найденый промежуток learning rate использовать для цикличного обучения модели, но я не был доволен результатом.

Эксперементы со слоями нейросети заняли тоже не мало времени. Вначале я все слои нейросети переучивал, потом попробывал
несколько слоев не переучивать, первые слои нейросети содержут всебе очень базовые признаки, следовательно я их и перестал
переучивать. В моей модели 4 первых не переученых слоя показали лучший результат. Дизайн верхушки нейросети я тоже подобрал
Самый хороший результат я получил с 512 нейронов в слои с регулиризацией l2 и дроп аут рэйт 0.5.

В оптимизаторе Адам я немного проэксперементировал с параметром beta_1, и для обучение нашел что значение 0.87 дало мне
результат получше. Затем я обучил модель основаную на сети Xception на 10 эпохах с фотографиями размером 224 на 224 и 
потом доучил модель на 2 эпохах с фотографиями размером 280 на 280. После этого я решил построить другую модель основаную
на другой сети.


